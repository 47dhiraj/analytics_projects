{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "import csv\n",
    "import feather\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = pd.read_csv('ratings.csv')\n",
    "# movies = pd.read_csv('movies.csv')\n",
    "# # posters = pd.read_csv('movie_posters.csv',header=None,names=['movieId','poster_url'],index_col=0)\n",
    "# ratings = pd.merge(movies,ratings).drop(['genres','timestamp'],axis=1)  # hamile garna lageko collaborative filtering chai user ko rating ko basis ma ho.. so hamilai genres and timestamp column ko khassai use nahune vayera.. tyo columns lai drop gareko ho\n",
    "# # ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_ratings = ratings.pivot_table(index=['userId'],columns=['title'],values='rating')\n",
    "# # user_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's Remove Movies which have less than 10 users who rated it. and fill remaining NaN with 0\n",
    "# user_ratings = user_ratings.dropna(thresh=5,axis=1).fillna(0)        # dropna(thresh=10,axis=1) --> yesko kaam vaneko,  jun column (i.e movie) ma 10 vanda kam users le rating deko xa.. testo column (axis=1 vannale column bujinxa) lai drop gar vaneko  & again,  fillna(0) ko kaam vaneko column drop gari sake paxi jati column bachxa .. bacheko column ma pani NaN value tw huna saki halxa.. so tyo NaN value lai 0 le replace garni vaneko... hamile Toy dataset ma 0 re place gare jastai ho  \n",
    "# # user_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's Build our Similarity Matrix\n",
    "# item_similarity_df = user_ratings.corr(method='pearson')         # Applying Pearson Correlation method    # Toy dataset ma cosine similarity use garda .. standardize method use garera 0 value lai hatauna ko lagi jasto chai yo Pearson Correlation ma garna pardaina.. i.e Pearson correlation method le automatically adjust for the mean.. so we dont have to apply our standardize method over here...\n",
    "# # item_similarity_df.to_csv(r'item_similarity_df.csv')\n",
    "# # item_similarity_df.head(50)\n",
    "\n",
    "\n",
    "# Reading dataframe from csv file\n",
    "# start = time.time()\n",
    "# item_similarity_df = pd.read_csv('item_similarity_df.csv', index_col = 0)\n",
    "# end = time.time()\n",
    "# print('Execution Time : ', end-start)\n",
    "\n",
    "\n",
    "# Reading dataframe from csv file in chunk\n",
    "# start = time.time()\n",
    "# chunks = pd.read_csv('item_similarity_df.csv', index_col = 0, chunksize=3591)\n",
    "# item_similarity_df = pd.concat(chunks)\n",
    "# end = time.time()\n",
    "# print('Execution Time : ', end-start)\n",
    "\n",
    "\n",
    "# Writing & Reading dataframe from pickle file (Best and also Fastest & also create less size .pkl file)\n",
    "# item_similarity_df.to_pickle('item_similarity_df.pkl')\n",
    "# start = time.time()\n",
    "# item_similarity_df = pd.read_pickle('item_similarity_df.pkl')\n",
    "# end = time.time()\n",
    "# print('Execution Time : ', end-start)\n",
    "# item_similarity_df.head(10)\n",
    "\n",
    "\n",
    "# Dumping & Loading dataframe from .pkl(pickle) file\n",
    "# with open('item_similarity_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(item_similarity_df, f)\n",
    "# start = time.time()\n",
    "# with open('item_similarity_df.pkl', 'rb') as f:\n",
    "#     item_similarity_df = pickle.load(f)\n",
    "# end = time.time()\n",
    "# print('Execution Time : ', end-start)\n",
    "# item_similarity_df.head(10)\n",
    "\n",
    "\n",
    "\n",
    "# Writing & Reading dataframe from feather fle (Best because threading is automatically handled)\n",
    "# path = 'item_similarity_df.feather'\n",
    "# # feather.write_dataframe(item_similarity_df, path)\n",
    "# start = time.time()\n",
    "# item_similarity_df = feather.read_dataframe(path, use_threads=True)     # feather file read garda threading ko pani facility cha (i.e use_threads=True le threading dincha)                   \n",
    "# item_similarity_df.head(10)\n",
    "# item_similarity_df.index = item_similarity_df.columns                   # feather file garda kheri row label hati auto hataucha.. so tei vayera manually hamile column labels ma ja naam cha tei naam row label ma rakheko\n",
    "# # end = time.time()\n",
    "# print('Execution Time : ', end-start)\n",
    "\n",
    "\n",
    "# Dumping to joblib file (Not that fast)\n",
    "# joblib.dump(item_similarity_df,\"item_similarity_df\")\n",
    "# To load Joblib file\n",
    "# start = time.time()\n",
    "# item_similarity_df = joblib.load('item_similarity_df')\n",
    "# end = time.time()\n",
    "# print('Execution Time : ', end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_similar_movies(movie_name,user_rating):                      # get_similar_movies() vanni chai method ho which accepts movie name ans user rating as parameters\n",
    "#     similar_score = item_similarity_df[movie_name]*(user_rating-2.5)\n",
    "#     similar_score = similar_score.sort_values(ascending=False)\n",
    "#     return similar_score                                            # get_similar_movies()  method return similar_score or similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def check_seen(movie, seen_movies):\n",
    "#     for item in seen_movies:\n",
    "#         if item == movie:\n",
    "#             return True\n",
    "\n",
    "#     return False\n",
    "\n",
    "# name = ['The Martian']\n",
    "# scifi_lover = [(\"The Martian\", 5)]\n",
    "# # #romantic_lover = [(\"Titanic (1997)\",5),(\"Up (2009)\",4),(\"Up (2009)\",4),(\"Kung Fu Panda (2008)\",4)]\n",
    "\n",
    "# similar_movies = pd.DataFrame()         # Empty datafram banayeko\n",
    "\n",
    "# for movie,rating in scifi_lover:\n",
    "#     similar_movies = similar_movies.append(get_similar_movies(movie,rating),ignore_index=True)\n",
    "\n",
    "# all_recommend = similar_movies.sum().sort_values(ascending=False)\n",
    " \n",
    " \n",
    "\n",
    "# i = 0\n",
    "# for movie, score in all_recommend.iteritems():\n",
    "#     if not check_seen(movie, name):\n",
    "#         print(movie,'\\t\\t\\t\\t\\t',  score)\n",
    "\n",
    "#     i = i + 1\n",
    "#     if i >= 36 + len(name):\n",
    "#         break\n",
    "\n",
    "        \n",
    "\n",
    "# end = time.time()\n",
    "# print('Execution Time : ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvkernel",
   "language": "python",
   "name": "venvkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
